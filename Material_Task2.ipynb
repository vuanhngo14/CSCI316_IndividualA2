{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 Artificial Neuron Network (ANN) in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discover and visualize data file `train.csv`\n",
    "1. Read in the data file using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>28.7967</th>\n",
       "      <th>16.0021</th>\n",
       "      <th>2.6449</th>\n",
       "      <th>0.3918</th>\n",
       "      <th>0.1982</th>\n",
       "      <th>27.7004</th>\n",
       "      <th>22.011</th>\n",
       "      <th>-8.2027</th>\n",
       "      <th>40.092</th>\n",
       "      <th>81.8828</th>\n",
       "      <th>g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.6036</td>\n",
       "      <td>11.7235</td>\n",
       "      <td>2.5185</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>26.2722</td>\n",
       "      <td>23.8238</td>\n",
       "      <td>-9.9574</td>\n",
       "      <td>6.3609</td>\n",
       "      <td>205.2610</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162.0520</td>\n",
       "      <td>136.0310</td>\n",
       "      <td>4.0612</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>116.7410</td>\n",
       "      <td>-64.8580</td>\n",
       "      <td>-45.2160</td>\n",
       "      <td>76.9600</td>\n",
       "      <td>256.7880</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.8172</td>\n",
       "      <td>9.5728</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>27.2107</td>\n",
       "      <td>-6.4633</td>\n",
       "      <td>-7.1513</td>\n",
       "      <td>10.4490</td>\n",
       "      <td>116.7370</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75.1362</td>\n",
       "      <td>30.9205</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>-5.5277</td>\n",
       "      <td>28.5525</td>\n",
       "      <td>21.8393</td>\n",
       "      <td>4.6480</td>\n",
       "      <td>356.4620</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.6240</td>\n",
       "      <td>21.1502</td>\n",
       "      <td>2.9085</td>\n",
       "      <td>0.2420</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>50.8761</td>\n",
       "      <td>43.1887</td>\n",
       "      <td>9.8145</td>\n",
       "      <td>3.6130</td>\n",
       "      <td>238.0980</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19014</th>\n",
       "      <td>21.3846</td>\n",
       "      <td>10.9170</td>\n",
       "      <td>2.6161</td>\n",
       "      <td>0.5857</td>\n",
       "      <td>0.3934</td>\n",
       "      <td>15.2618</td>\n",
       "      <td>11.5245</td>\n",
       "      <td>2.8766</td>\n",
       "      <td>2.4229</td>\n",
       "      <td>106.8258</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19015</th>\n",
       "      <td>28.9452</td>\n",
       "      <td>6.7020</td>\n",
       "      <td>2.2672</td>\n",
       "      <td>0.5351</td>\n",
       "      <td>0.2784</td>\n",
       "      <td>37.0816</td>\n",
       "      <td>13.1853</td>\n",
       "      <td>-2.9632</td>\n",
       "      <td>86.7975</td>\n",
       "      <td>247.4560</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19016</th>\n",
       "      <td>75.4455</td>\n",
       "      <td>47.5305</td>\n",
       "      <td>3.4483</td>\n",
       "      <td>0.1417</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>-9.3561</td>\n",
       "      <td>41.0562</td>\n",
       "      <td>-9.4662</td>\n",
       "      <td>30.2987</td>\n",
       "      <td>256.5166</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19017</th>\n",
       "      <td>120.5135</td>\n",
       "      <td>76.9018</td>\n",
       "      <td>3.9939</td>\n",
       "      <td>0.0944</td>\n",
       "      <td>0.0683</td>\n",
       "      <td>5.8043</td>\n",
       "      <td>-93.5224</td>\n",
       "      <td>-63.8389</td>\n",
       "      <td>84.6874</td>\n",
       "      <td>408.3166</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19018</th>\n",
       "      <td>187.1814</td>\n",
       "      <td>53.0014</td>\n",
       "      <td>3.2093</td>\n",
       "      <td>0.2876</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>-167.3125</td>\n",
       "      <td>-168.4558</td>\n",
       "      <td>31.4755</td>\n",
       "      <td>52.7310</td>\n",
       "      <td>272.3174</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19019 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        28.7967   16.0021  2.6449  0.3918  0.1982   27.7004    22.011  \\\n",
       "0       31.6036   11.7235  2.5185  0.5303  0.3773   26.2722   23.8238   \n",
       "1      162.0520  136.0310  4.0612  0.0374  0.0187  116.7410  -64.8580   \n",
       "2       23.8172    9.5728  2.3385  0.6147  0.3922   27.2107   -6.4633   \n",
       "3       75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277   28.5525   \n",
       "4       51.6240   21.1502  2.9085  0.2420  0.1340   50.8761   43.1887   \n",
       "...         ...       ...     ...     ...     ...       ...       ...   \n",
       "19014   21.3846   10.9170  2.6161  0.5857  0.3934   15.2618   11.5245   \n",
       "19015   28.9452    6.7020  2.2672  0.5351  0.2784   37.0816   13.1853   \n",
       "19016   75.4455   47.5305  3.4483  0.1417  0.0549   -9.3561   41.0562   \n",
       "19017  120.5135   76.9018  3.9939  0.0944  0.0683    5.8043  -93.5224   \n",
       "19018  187.1814   53.0014  3.2093  0.2876  0.1539 -167.3125 -168.4558   \n",
       "\n",
       "       -8.2027   40.092   81.8828  g  \n",
       "0      -9.9574   6.3609  205.2610  g  \n",
       "1     -45.2160  76.9600  256.7880  g  \n",
       "2      -7.1513  10.4490  116.7370  g  \n",
       "3      21.8393   4.6480  356.4620  g  \n",
       "4       9.8145   3.6130  238.0980  g  \n",
       "...        ...      ...       ... ..  \n",
       "19014   2.8766   2.4229  106.8258  h  \n",
       "19015  -2.9632  86.7975  247.4560  h  \n",
       "19016  -9.4662  30.2987  256.5166  h  \n",
       "19017 -63.8389  84.6874  408.3166  h  \n",
       "19018  31.4755  52.7310  272.3174  h  \n",
       "\n",
       "[19019 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv(\"../magic04.data\")\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Display information of the dataset that is just read in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19019 entries, 0 to 19018\n",
      "Data columns (total 11 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   28.7967  19019 non-null  float64\n",
      " 1   16.0021  19019 non-null  float64\n",
      " 2   2.6449   19019 non-null  float64\n",
      " 3   0.3918   19019 non-null  float64\n",
      " 4   0.1982   19019 non-null  float64\n",
      " 5   27.7004  19019 non-null  float64\n",
      " 6   22.011   19019 non-null  float64\n",
      " 7   -8.2027  19019 non-null  float64\n",
      " 8   40.092   19019 non-null  float64\n",
      " 9   81.8828  19019 non-null  float64\n",
      " 10  g        19019 non-null  object \n",
      "dtypes: float64(10), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Display important statistic attribute of all features to see whether to drop any not column that has large differences in the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>28.7967</th>\n",
       "      <th>16.0021</th>\n",
       "      <th>2.6449</th>\n",
       "      <th>0.3918</th>\n",
       "      <th>0.1982</th>\n",
       "      <th>27.7004</th>\n",
       "      <th>22.011</th>\n",
       "      <th>-8.2027</th>\n",
       "      <th>40.092</th>\n",
       "      <th>81.8828</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19019.000000</td>\n",
       "      <td>19019.000000</td>\n",
       "      <td>19019.000000</td>\n",
       "      <td>19019.000000</td>\n",
       "      <td>19019.000000</td>\n",
       "      <td>19019.000000</td>\n",
       "      <td>19019.000000</td>\n",
       "      <td>19019.000000</td>\n",
       "      <td>19019.000000</td>\n",
       "      <td>19019.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>53.251440</td>\n",
       "      <td>22.181291</td>\n",
       "      <td>2.825026</td>\n",
       "      <td>0.380326</td>\n",
       "      <td>0.214658</td>\n",
       "      <td>-4.333429</td>\n",
       "      <td>10.544942</td>\n",
       "      <td>0.250170</td>\n",
       "      <td>27.645052</td>\n",
       "      <td>193.823912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>42.365598</td>\n",
       "      <td>18.346484</td>\n",
       "      <td>0.472609</td>\n",
       "      <td>0.182818</td>\n",
       "      <td>0.110514</td>\n",
       "      <td>59.207163</td>\n",
       "      <td>51.001391</td>\n",
       "      <td>20.827896</td>\n",
       "      <td>26.104151</td>\n",
       "      <td>74.729344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.283500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.941300</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>-457.916100</td>\n",
       "      <td>-331.780000</td>\n",
       "      <td>-205.894700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.282600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.336000</td>\n",
       "      <td>11.863700</td>\n",
       "      <td>2.477100</td>\n",
       "      <td>0.235800</td>\n",
       "      <td>0.128450</td>\n",
       "      <td>-20.588300</td>\n",
       "      <td>-12.845050</td>\n",
       "      <td>-10.849750</td>\n",
       "      <td>5.546950</td>\n",
       "      <td>142.499000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.149000</td>\n",
       "      <td>17.140600</td>\n",
       "      <td>2.739600</td>\n",
       "      <td>0.354100</td>\n",
       "      <td>0.196500</td>\n",
       "      <td>4.011900</td>\n",
       "      <td>15.309400</td>\n",
       "      <td>0.689800</td>\n",
       "      <td>17.677000</td>\n",
       "      <td>191.856900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70.126850</td>\n",
       "      <td>24.739950</td>\n",
       "      <td>3.101600</td>\n",
       "      <td>0.503700</td>\n",
       "      <td>0.285250</td>\n",
       "      <td>24.060350</td>\n",
       "      <td>35.844100</td>\n",
       "      <td>10.947050</td>\n",
       "      <td>45.884100</td>\n",
       "      <td>240.564550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>334.177000</td>\n",
       "      <td>256.382000</td>\n",
       "      <td>5.323300</td>\n",
       "      <td>0.893000</td>\n",
       "      <td>0.675200</td>\n",
       "      <td>575.240700</td>\n",
       "      <td>238.321000</td>\n",
       "      <td>179.851000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>495.561000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            28.7967       16.0021        2.6449        0.3918        0.1982  \\\n",
       "count  19019.000000  19019.000000  19019.000000  19019.000000  19019.000000   \n",
       "mean      53.251440     22.181291      2.825026      0.380326      0.214658   \n",
       "std       42.365598     18.346484      0.472609      0.182818      0.110514   \n",
       "min        4.283500      0.000000      1.941300      0.013100      0.000300   \n",
       "25%       24.336000     11.863700      2.477100      0.235800      0.128450   \n",
       "50%       37.149000     17.140600      2.739600      0.354100      0.196500   \n",
       "75%       70.126850     24.739950      3.101600      0.503700      0.285250   \n",
       "max      334.177000    256.382000      5.323300      0.893000      0.675200   \n",
       "\n",
       "            27.7004        22.011       -8.2027        40.092       81.8828  \n",
       "count  19019.000000  19019.000000  19019.000000  19019.000000  19019.000000  \n",
       "mean      -4.333429     10.544942      0.250170     27.645052    193.823912  \n",
       "std       59.207163     51.001391     20.827896     26.104151     74.729344  \n",
       "min     -457.916100   -331.780000   -205.894700      0.000000      1.282600  \n",
       "25%      -20.588300    -12.845050    -10.849750      5.546950    142.499000  \n",
       "50%        4.011900     15.309400      0.689800     17.677000    191.856900  \n",
       "75%       24.060350     35.844100     10.947050     45.884100    240.564550  \n",
       "max      575.240700    238.321000    179.851000     90.000000    495.561000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Print out the correlation of the features and the target to find out their relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'g'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataframe\u001b[39m.\u001b[39;49mcorr()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:10054\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[1;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[0;32m  10052\u001b[0m cols \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcolumns\n\u001b[0;32m  10053\u001b[0m idx \u001b[39m=\u001b[39m cols\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m> 10054\u001b[0m mat \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mto_numpy(dtype\u001b[39m=\u001b[39;49m\u001b[39mfloat\u001b[39;49m, na_value\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mnan, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m  10056\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpearson\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m  10057\u001b[0m     correl \u001b[39m=\u001b[39m libalgos\u001b[39m.\u001b[39mnancorr(mat, minp\u001b[39m=\u001b[39mmin_periods)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:1838\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1836\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1837\u001b[0m     dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdtype(dtype)\n\u001b[1;32m-> 1838\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mas_array(dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, na_value\u001b[39m=\u001b[39;49mna_value)\n\u001b[0;32m   1839\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mdtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m dtype:\n\u001b[0;32m   1840\u001b[0m     result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(result, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:1732\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1730\u001b[0m         arr\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mwriteable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1732\u001b[0m     arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interleave(dtype\u001b[39m=\u001b[39;49mdtype, na_value\u001b[39m=\u001b[39;49mna_value)\n\u001b[0;32m   1733\u001b[0m     \u001b[39m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1734\u001b[0m     \u001b[39m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1736\u001b[0m \u001b[39mif\u001b[39;00m na_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m lib\u001b[39m.\u001b[39mno_default:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:1794\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1792\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1793\u001b[0m         arr \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39mget_values(dtype)\n\u001b[1;32m-> 1794\u001b[0m     result[rl\u001b[39m.\u001b[39;49mindexer] \u001b[39m=\u001b[39m arr\n\u001b[0;32m   1795\u001b[0m     itemmask[rl\u001b[39m.\u001b[39mindexer] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1797\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m itemmask\u001b[39m.\u001b[39mall():\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'g'"
     ]
    }
   ],
   "source": [
    "dataframe.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize data\n",
    "#### Visualize the target class values to see if there is any abnormal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'critical_temp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'critical_temp'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[39m.\u001b[39mhist(dataframe[\u001b[39m'\u001b[39;49m\u001b[39mcritical_temp\u001b[39;49m\u001b[39m'\u001b[39;49m], edgecolor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaroon\u001b[39m\u001b[39m'\u001b[39m, facecolor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39morangered\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m\"\u001b[39m\u001b[39mTemperature (Celsius)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m\"\u001b[39m\u001b[39mNumber of temperature label\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'critical_temp'"
     ]
    }
   ],
   "source": [
    "plt.hist(dataframe['critical_temp'], edgecolor='maroon', facecolor='orangered')\n",
    "plt.xlabel(\"Temperature (Celsius)\")\n",
    "plt.ylabel(\"Number of temperature label\")\n",
    "plt.title(\"Temperature of for the target class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the number of elements feature to see if there is any abnormal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dataframe['number_of_elements'], edgecolor='maroon', facecolor='orangered')\n",
    "plt.xlabel(\"Numbers of elements\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Features numbers of elements data distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking null value in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a copy of dataset, then split into 2/3 for training and the rest for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataframe.copy()\n",
    "\n",
    "X = df.drop(columns=['critical_temp'])\n",
    "y = df['critical_temp']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scaling\n",
    "Since it is a linear regression problem ( which aims to find the best-fitting line that describes the relationship between the independent variables (features) and the dependent variable (target)), scaling all feature and the target class to optimize the algorithm of finding the best fitting line and also help the learning model to be trained faster.\n",
    "1. Using MinMaxScaler()\n",
    "2. fit into the object of this scaler training features dataset\n",
    "3. Using that standard to scale the testing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m scaler \u001b[39m=\u001b[39m MinMaxScaler()\n\u001b[1;32m----> 3\u001b[0m scaler\u001b[39m.\u001b[39mfit(X_train)\n\u001b[0;32m      5\u001b[0m X_train \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform(X_train)\n\u001b[0;32m      6\u001b[0m X_test \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform the target with same method of fitting the training label to the scaler\n",
    "and scale the testing target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(y_train.values.reshape(-1,1))\n",
    "y_train = scaler.transform(y_train.values.reshape(-1,1))\n",
    "y_train = y_train.reshape(-1)\n",
    "y_train = pd.Series(y_train)\n",
    "y_test = scaler.transform(y_test.values.reshape(-1,1))\n",
    "y_test = y_test.reshape(-1)\n",
    "y_test = pd.Series(y_test)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the training data set into two subsets, one for training and one for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = X_train[:3000]\n",
    "partial_X_train = X_train[3000:]\n",
    "y_val = y_train[:3000]\n",
    "partial_y_train = y_train[3000:]\n",
    "partial_X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a function to build a artificial neuron network using Keras API\n",
    "1. `build_model()` function takes in for parameters\n",
    "    * Number of hidden layers : `n_hidden`\n",
    "    * Number of neurons of each layer : `n_neurons`\n",
    "    * Regularization number (L1, L2): `a`, `b`\n",
    "2. Model using the optimizers of `RMSprop` with a `learning_rate` equals 0.0002\n",
    "3. Model using Mean Squared Error as a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from keras.applications.densenet import layers\n",
    "from keras import metrics\n",
    "\n",
    "optimizer=keras.optimizers.Adam()\n",
    "def build_model(n_hidden= 3, n_neurons = 32, a = 0.001, b=0.002):\n",
    "    model = keras.Sequential()\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(layers.Dense(n_neurons, activation = 'relu', kernel_regularizer=regularizers.L1L2(l1=a, l2=b)))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer=optimizer, loss=keras.losses.MeanSquaredError(), metrics=[metrics.MeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitting a model training data subset**\n",
    "* With 60 iterations and a `batch_size` for dataset of 512\n",
    "* Print out two loss with a validation dataset when fit into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "history = model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=50,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict a temperature for a testing data using the trained model above and print out the results**\n",
    "* Inserse the prediction into original scale to be friendlier in reading the data temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the two loss during fitting into the model to check the efficiency of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mse = history.history['mean_squared_error']\n",
    "var = np.std(y)**2\n",
    "def r_squared(mse, var):\n",
    "    return (1-mse/var)\n",
    "\n",
    "for i in range(len(mse)):\n",
    "    print(r_squared(mse[i], var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history_dict = history.history\n",
    "loss_values = history_dict[\"loss\"]\n",
    "val_loss_values = history_dict[\"val_loss\"]\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f'Test accuracy: {score[1]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tune model\n",
    "To make the model become more accurate by implementing:\n",
    "* Fine tune some hyperparameter of number of hidden layers `n_hidden`, numeber of neurons `n_neurons`\n",
    "* Changing the regularization L1 and L2 to reduce the loss and not become overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs = {\n",
    "    'n_hidden': [2,4,6],\n",
    "    'n_neurons': [32,64],\n",
    "    'a': [0.0002, 0.001],\n",
    "    'b': [0.0002, 0.001]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a model and choose the best hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_cv = GridSearchCV(keras_reg, param_distribs, cv = 3)\n",
    "search_cv.fit(partial_X_train, partial_y_train, epochs=60,validation_data=(x_val,y_val), \\\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=30)])\n",
    "search_cv.best_params_\n",
    "search_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print out the best parameters after hypertuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = search_cv.best_estimator_.model\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluating the model and making predictions after hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.evaluate(X_train, y_train)\n",
    "best_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.evaluate(np.array(X_test),np.array(y_test))\n",
    "best_model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
