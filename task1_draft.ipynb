{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data set\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf = df.sample(n=50000, random_state=42)\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_file = '../customer_churn_dataset-testing-master.csv'\n",
    "train_file = '../customer_churn_dataset-training-master.csv'\n",
    "\n",
    "test_df = pd.read_csv(test_file)\n",
    "train_df = pd.read_csv(train_file)\n",
    "\n",
    "\n",
    "df = pd.concat([train_df, test_df], axis=0)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "'''\n",
    "df = df.sample(n=50000, random_state=42)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_classification(y_true, y_pred):\n",
    "\n",
    "    auroc = roc_auc_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    print(\"AUROC:\", auroc)\n",
    "    print(\"F1-Score:\", f1)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing values \n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z Score normalization for Last Interaction \n",
    "\n",
    "normalized_last_interaction = (df['Last Interaction'] - df['Last Interaction'].mean()) / df['Last Interaction'].std()\n",
    "\n",
    "# Replace the previous Last Interaction with new one \n",
    "df['Last Interaction'] = normalized_last_interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5 bins for attribute Total Spend \n",
    "\n",
    "bin_labels = ['Bin 1', 'Bin 2', 'Bin 3', 'Bin 4', 'Bin 5']\n",
    "\n",
    "df['Total Spend'] = pd.cut(df['Total Spend'], bins=5, labels=bin_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Usage Frequency</th>\n",
       "      <th>Support Calls</th>\n",
       "      <th>Payment Delay</th>\n",
       "      <th>Subscription Type</th>\n",
       "      <th>Contract Length</th>\n",
       "      <th>Total Spend</th>\n",
       "      <th>Last Interaction</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Annual</td>\n",
       "      <td>Bin 5</td>\n",
       "      <td>0.277572</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>Bin 3</td>\n",
       "      <td>-1.000267</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Quarterly</td>\n",
       "      <td>Bin 1</td>\n",
       "      <td>-1.348768</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>38.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>Bin 2</td>\n",
       "      <td>1.671578</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>Bin 3</td>\n",
       "      <td>0.626073</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID   Age  Gender  Tenure  Usage Frequency  Support Calls  \\\n",
       "0         2.0  30.0  Female    39.0             14.0            5.0   \n",
       "1         3.0  65.0  Female    49.0              1.0           10.0   \n",
       "2         4.0  55.0  Female    14.0              4.0            6.0   \n",
       "3         5.0  58.0    Male    38.0             21.0            7.0   \n",
       "4         6.0  23.0    Male    32.0             20.0            5.0   \n",
       "\n",
       "   Payment Delay Subscription Type Contract Length Total Spend  \\\n",
       "0           18.0          Standard          Annual       Bin 5   \n",
       "1            8.0             Basic         Monthly       Bin 3   \n",
       "2           18.0             Basic       Quarterly       Bin 1   \n",
       "3            7.0          Standard         Monthly       Bin 2   \n",
       "4            8.0             Basic         Monthly       Bin 3   \n",
       "\n",
       "   Last Interaction  Churn  \n",
       "0          0.277572    1.0  \n",
       "1         -1.000267    1.0  \n",
       "2         -1.348768    1.0  \n",
       "3          1.671578    1.0  \n",
       "4          0.626073    1.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unecessary columns \n",
    "\n",
    "df.drop('CustomerID', axis=1, inplace=True)\n",
    "\n",
    "# Drop gender to ensure equality \n",
    "df.drop('Gender', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, gain=0, y=None, *, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "        self.gain = gain\n",
    "        self.y = y\n",
    "        self.count = Counter(y)\n",
    "\n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None\n",
    "\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, min_samples_split=2, max_depth=100, depth=None, n_features=None, criterion=\"GINI\"):\n",
    "        self.labels = None\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.n_features = n_features\n",
    "        self.root = None\n",
    "        self.depth = depth if depth else 0\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_features = X.shape[1] if not self.n_features else min(X.shape[1], self.n_features)\n",
    "        self.labels = X.columns\n",
    "        self.root = self._grow_tree(X, y)\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        n_labels = len(np.unique(y))\n",
    "\n",
    "        if depth >= self.max_depth or n_labels == 1 or n_samples < self.min_samples_split:\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return Node(value=leaf_value, y=y)\n",
    "\n",
    "        feat_idxs = np.random.choice(n_features, self.n_features, replace=False)\n",
    "        best_feature, best_threshold, best_gain = self._best_split(X, y, feat_idxs)\n",
    "\n",
    "        left_idxs, right_idxs = self._split(X.iloc[:, best_feature], best_threshold)\n",
    "        left = self._grow_tree(X.iloc[left_idxs, :], y.iloc[left_idxs], depth + 1)\n",
    "        right = self._grow_tree(X.iloc[right_idxs, :], y.iloc[right_idxs], depth + 1)\n",
    "        return Node(best_feature, best_threshold, left, right, best_gain, y)\n",
    "\n",
    "    def _best_split(self, X, y, feat_idxs):\n",
    "        best_gain = -1\n",
    "        best_split_idx, best_split_threshold = None, None\n",
    "\n",
    "        for feat_idx in feat_idxs:\n",
    "            X_column = X.iloc[:, feat_idx]\n",
    "            thresholds = np.unique(X_column)\n",
    "\n",
    "            for thr in thresholds:\n",
    "                if self.criterion == \"GINI\":\n",
    "                    gain = self._gini_gain(y, X_column, thr)\n",
    "                elif self.criterion == \"GAIN_RATIO\":\n",
    "                    gain = self._gain_ratio(y, X_column, thr)\n",
    "                else:\n",
    "                    gain = self._information_gain(y, X_column, thr)\n",
    "\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_split_idx = feat_idx\n",
    "                    best_split_threshold = thr\n",
    "\n",
    "        return best_split_idx, best_split_threshold, best_gain\n",
    "\n",
    "    def _gini_gain(self, y, X_column, threshold):\n",
    "        gini_base = self._get_gini(y)\n",
    "\n",
    "        left_idxs, right_idxs = self._split(X_column, threshold)\n",
    "        left_counts = Counter(y.iloc[left_idxs])\n",
    "        right_counts = Counter(y.iloc[right_idxs])\n",
    "\n",
    "        left_class0_count = Counter(left_counts).get(0, 0)\n",
    "        left_class1_count = Counter(left_counts).get(1, 0)\n",
    "        right_class0_count = Counter(right_counts).get(0, 0)\n",
    "        right_class1_count = Counter(right_counts).get(1, 0)\n",
    "\n",
    "        gini_left = self._gini_impurity(left_class0_count, left_class1_count)\n",
    "        gini_right = self._gini_impurity(right_class0_count, right_class1_count)\n",
    "\n",
    "        n_left = left_class0_count + left_class1_count\n",
    "        n_right = right_class0_count + right_class1_count\n",
    "\n",
    "        w_left = n_left / (n_left + n_right)\n",
    "        w_right = n_right / (n_left + n_right)\n",
    "\n",
    "        w_gini = w_left * gini_left + w_right * gini_right\n",
    "\n",
    "        gini_gain = gini_base - w_gini\n",
    "        return gini_gain\n",
    "\n",
    "    def _get_gini(self, y):\n",
    "        class0_count = Counter(y).get(0, 0)\n",
    "        class1_count = Counter(y).get(1, 0)\n",
    "        return self._gini_impurity(class0_count, class1_count)\n",
    "\n",
    "    def _gini_impurity(self, class0_count, class1_count):\n",
    "        if class0_count is None:\n",
    "            class0_count = 0\n",
    "        if class1_count is None:\n",
    "            class1_count = 0\n",
    "        n = class0_count + class1_count\n",
    "\n",
    "        if n == 0:\n",
    "            return 0.0\n",
    "\n",
    "        p0 = class0_count / n\n",
    "        p1 = class1_count / n\n",
    "        gini = 1 - (p0 ** 2 + p1 ** 2)\n",
    "        return gini\n",
    "\n",
    "    def _gain_ratio(self, y, X_column, threshold):\n",
    "        parent_entropy = self._entropy(y)\n",
    "        left_idxs, right_idxs = self._split(X_column, threshold)\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return 0\n",
    "\n",
    "        n = len(y)\n",
    "        n_left, n_right = len(left_idxs), len(right_idxs)\n",
    "        e_left, e_right = self._entropy(y.iloc[left_idxs]), self._entropy(y.iloc[right_idxs])\n",
    "        child_entropy = (n_left / n) * e_left + (n_right / n) * e_right\n",
    "\n",
    "        information_gain = parent_entropy - child_entropy\n",
    "\n",
    "        split_info = -(n_left / n * np.log(n_left / n) + n_right / n * np.log(n_right / n))\n",
    "\n",
    "        return information_gain / split_info\n",
    "\n",
    "    def _information_gain(self, y, X_column, threshold):\n",
    "        parent_entropy = self._entropy(y)\n",
    "        left_idxs, right_idxs = self._split(X_column, threshold)\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return 0\n",
    "\n",
    "        n = len(y)\n",
    "        n_left, n_right = len(left_idxs), len(right_idxs)\n",
    "        e_left, e_right = self._entropy(y.iloc[left_idxs]), self._entropy(y.iloc[right_idxs])\n",
    "        child_entropy = (n_left / n) * e_left + (n_right / n) * e_right\n",
    "\n",
    "        information_gain = parent_entropy - child_entropy\n",
    "        return information_gain\n",
    "\n",
    "    def _split(self, X_column, split_threshold):\n",
    "        left_idxs = np.argwhere(X_column.to_numpy() <= split_threshold).flatten()\n",
    "        right_idxs = np.argwhere(X_column.to_numpy() > split_threshold).flatten()\n",
    "        return left_idxs, right_idxs\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        hist = np.bincount(y)\n",
    "        ps = hist / len(y)\n",
    "        return -np.sum([p * np.log(p) for p in ps if p > 0])\n",
    "\n",
    "    def _most_common_label(self, y):\n",
    "        counter = Counter(y)\n",
    "        if len(Counter(y).most_common(1)) == 0:\n",
    "            value = None\n",
    "        else:\n",
    "            value = counter.most_common(1)[0][0]\n",
    "        return value\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._traverse_tree(x, self.root) for idx, x in X.iterrows()])\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        if node.is_leaf_node() or node.feature is None:\n",
    "            return node.value\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        return self._traverse_tree(x, node.right)\n",
    "\n",
    "    def counter_to_str(self, counter: Counter):\n",
    "        inside = [f\"{key}: {value}\" for key, value in counter.items()]\n",
    "        return f\"({', '.join(inside)})\"\n",
    "\n",
    "    def print_info(self, node, depth):\n",
    "        if node.feature is None:\n",
    "            return\n",
    "\n",
    "        preamble0 = ' ' * depth * 2 + ('\\t\\t' if depth > 0 else '')\n",
    "\n",
    "        print(f\"{preamble0} {self.labels[node.feature]} <= {node.threshold} ? {node.gain}\")\n",
    "\n",
    "        self.print_info(node.left, depth + 1)\n",
    "        self.print_info(node.right, depth + 1)\n",
    "\n",
    "    def print_tree(self):\n",
    "        self.print_info(self.root, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Splitting into features (X) and target (y)\n",
    "X = df.drop(\"Churn\", axis=1)\n",
    "y = df[\"Churn\"]\n",
    "\n",
    "# Splitting into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest based on DT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method used to create this random forest <br>\n",
    "<br>\n",
    "\n",
    "Random forest is advanced version tree, which includes multiple decision trees. This apply the same logic, which I will create multiple decision tree, train them and make prediction for each of the decision tree. And then, the results are aggregated, and then get the mean to get the final prediction. <br> \n",
    "\n",
    "The random forest is better because it will be roburst to noise and outliers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, n_estimators=100, max_depth=12, criterion=\"GAIN_RATIO\", min_samples_split=2, n_features=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.criterion = criterion\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.n_features = n_features\n",
    "        self.estimators = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for _ in range(self.n_estimators):\n",
    "            subset_indices = np.random.choice(len(X), len(X), replace=True)\n",
    "            subset_X, subset_y = X.iloc[subset_indices], y.iloc[subset_indices]\n",
    "\n",
    "            tree = DecisionTree(max_depth=self.max_depth, criterion=self.criterion,\n",
    "                                min_samples_split=self.min_samples_split, n_features=self.n_features)\n",
    "            tree.fit(subset_X, subset_y)\n",
    "            self.estimators.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.array([tree.predict(X) for tree in self.estimators])\n",
    "        return np.round(np.mean(predictions, axis=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate <strong>Random Forest</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and train the RandomForest\n",
    "rf = RandomForest(n_estimators=85, max_depth=12, criterion=\"GAIN_RATIO\", min_samples_split=2, n_features=None)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the RandomForest\n",
    "predictions_rf = rf.predict(X_test)\n",
    "\n",
    "# EST: 11m for 100 DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.9177499262088125\n",
      "F1-Score: 0.9345289947903322\n",
      "Precision: 0.8964918317521179\n",
      "Recall: 0.9759369258486291\n",
      "Accuracy: 0.924130559569288\n"
     ]
    }
   ],
   "source": [
    "# Check accuracy of the random forest\n",
    "\n",
    "evaluate_classification(y_test, predictions_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate <strong>decision tree</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a decision tree - Gain_Ratio\n",
    "clf_gain = DecisionTree(max_depth=11, criterion=\"GAIN_RATIO\")\n",
    "clf_gain.fit(X_train, y_train)\n",
    "\n",
    "predictions_gain_ratio = clf_gain.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.9166877959349955\n",
      "F1-Score: 0.9333629839971946\n",
      "Precision: 0.8965919547784935\n",
      "Recall: 0.9732791066873584\n",
      "Accuracy: 0.9228934502484115\n"
     ]
    }
   ],
   "source": [
    "evaluate_classification(y_test, predictions_gain_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the comprehensive evaluation metrics, it is evident that the Random Forest outperforms the Decision Tree across various measurements, including AUROC, F1-Score, precision, recall, and accuracy. This improvement highlights the ensemble nature of Random Forest, which leverages multiple decision trees to enhance predictive performance. However, it's important to note that this custom Random Forest implementation, while exhibiting notable advancements, may not be as optimized as established libraries like scikit-learn's Random Forest, due to being developed from scratch."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
